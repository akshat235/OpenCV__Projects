{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'F:\\faltu\\batman.jpg')\n",
    "cv2.imshow('pi678c', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)#width\n",
    "cap.set(4,480)#height\n",
    "cap.set(10,100) #brightness\n",
    "while(True):\n",
    "    suc,frame = cap.read()\n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(1) &0xFF == ord(' '):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLUR\n",
    "img = cv2.imread('j1.jpg')\n",
    "\n",
    "grayimg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgblur=cv2.GaussianBlur(grayimg,(3,3),0)\n",
    "imgblurr=cv2.GaussianBlur(grayimg,(9,9),0)\n",
    "cv2.imshow('pic', grayimg)\n",
    "cv2.imshow('ppic', imgblur)w\n",
    "cv2.imshow('ppice', imgblurr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDGE \n",
    "img = cv2.imread('j1.jpg')\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "grayimg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgblur=cv2.GaussianBlur(grayimg,(3,3),0)\n",
    "imgcanny = cv2.Canny(img,250,150)\n",
    "imgDialate=cv2.dilate(imgcanny, kernel, iterations =1) #increase width of edge\n",
    "# more iteration means more thickness of image\n",
    "imgEroded=cv2.erode(imgDialate, kernel, iterations = 1)\n",
    "\n",
    "cv2.imshow('pic', grayimg)\n",
    "cv2.imshow('pppic', imgblur)\n",
    "cv2.imshow('Edge Detection', imgcanny)\n",
    "cv2.imshow('Dialated image', imgDialate)\n",
    "cv2.imshow('Erorded Image', imgEroded)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROP\n",
    "img = cv2.imread('j1.jpg')\n",
    "\n",
    "imgcropped = img[0:500,200:700]\n",
    "\n",
    "cv2.imshow('ppice', imgcropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "#generate image from np lib\n",
    "\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "#img[100:200,100:200]=0,0,0\n",
    "print(img.shape)\n",
    "\n",
    "#Putting text and shapes on images \n",
    "\n",
    "#cv2.line(image_source,start,end,color,thickness)\n",
    "cv2.line(img,(0,0),(int(img.shape[1]/2),img.shape[0]),(0,255,255),2)\n",
    "cv2.rectangle(img,(100,100),(250,350),(0,255,25),1)\n",
    "cv2.circle(img,(int(img.shape[1]/2),int(img.shape[0]/2)), 50, (255,55,45),5)\n",
    "\n",
    "cv2.putText(img,\"Hello You\", (250,160), cv2.FONT_HERSHEY_COMPLEX,1.5,(199,180,0),2)\n",
    "\n",
    "cv2.imshow('picture', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# warp perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('w2.png')\n",
    "\n",
    "w,h=250,350\n",
    "\n",
    "pts1= np.float32([[545,193],[695,228],[459,369],[626,416]])\n",
    "pts2 = np.float32([[0,0],[w,0],[0,h],[w,h]])\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "output = cv2.warpPerspective(img,matrix,(w,h))\n",
    "\n",
    "cv2.imshow('picccctre', img)\n",
    "cv2.imshow('picture',output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WarpPerspective from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0) \n",
    "  \n",
    "while True: \n",
    "      \n",
    "    ret, frame = cap.read() \n",
    "  \n",
    "    # Locate points of the documents or object which you want to transform \n",
    "    pts1 = np.float32([[0, 260], [340, 260], [0, 400], [340, 400]]) \n",
    "    pts2 = np.float32([[0, 0], [300, 0], [0, 640], [300, 640]]) \n",
    "      \n",
    "    # Apply Perspective Transform Algorithm \n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2) \n",
    "    result = cv2.warpPerspective(frame, matrix, (1200, 600)) \n",
    "    # Wrap the transformed image \n",
    "  \n",
    "    cv2.imshow('frame', frame) # Inital Capture \n",
    "    cv2.imshow('frame1', result) # Transformed Capture \n",
    "  \n",
    "    if cv2.waitKey(1) &0xFF == ord(' '): \n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental\n",
    "#extract and stack image\n",
    "\n",
    "img = cv2.imread('w2.png')\n",
    "w,h=250,350\n",
    "\n",
    "pts1= np.float32([[545,193],[695,228],[459,369],[626,416]])\n",
    "pts2 = np.float32([[0,0],[w,0],[0,h],[w,h]])\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "output = cv2.warpPerspective(img,matrix,(w,h))\n",
    "imgstack = np.hstack((output,output))\n",
    "imgstackv = np.vstack((imgstack,imgstack))\n",
    "\n",
    "cv2.imshow('picccctre', img)\n",
    "cv2.imshow('piccctre', imgstackv)\n",
    "cv2.imshow('picture',output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting color in image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('veg.jpg')\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",600,240)\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "#cv2.createTrackbar(\"name\",\"nameoftrackbar\",minvalue,maxvalue(upto180 in opencv i.e. 179),function that runs \n",
    "#everytime trackbar changes) )\n",
    "try:    \n",
    "    cv2.createTrackbar(\"Hue_min\",\"TrackBars\",0,179,empty )\n",
    "    cv2.createTrackbar(\"Hue_max\",\"TrackBars\",23,179,empty )\n",
    "    cv2.createTrackbar(\"Sat_min\",\"TrackBars\",128,255,empty )\n",
    "    cv2.createTrackbar(\"Sat_max\",\"TrackBars\",255,255,empty )\n",
    "    cv2.createTrackbar(\"Val_min\",\"TrackBars\",166,255,empty )\n",
    "    cv2.createTrackbar(\"Val_max\",\"TrackBars\",255,255,empty )\n",
    "except:\n",
    "    print('dfsd')\n",
    "#read trackbar values\n",
    "while(True):\n",
    "    h_min = cv2.getTrackbarPos(\"Hue_min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue_max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat_min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat_max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val_min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val_max\",\"TrackBars\")\n",
    "    \n",
    "    lower= np.array([h_min,s_min,v_min])\n",
    "    upper= np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "   \n",
    "    imgresult = cv2.bitwise_and(img,img,mask = mask)\n",
    "    \n",
    "    # print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "\n",
    "    cv2.imshow('pictur',img)\n",
    "    cv2.imshow('result',imgresult)\n",
    "    cv2.imshow('pictureHSV',imgHSV)\n",
    "    cv2.imshow('picturemask',mask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To detect colors as per your choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-95hbg2jt\\opencv\\modules\\core\\src\\arithm.cpp:234: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-56d7a8dfc5bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgHSV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mimgresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# print(h_min,h_max,s_min,s_max,v_min,v_max)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-95hbg2jt\\opencv\\modules\\core\\src\\arithm.cpp:234: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('veg.jpg')\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",600,240)\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "#cv2.createTrackbar(\"name\",\"nameoftrackbar\",minvalue,maxvalue(upto180 in opencv i.e. 179),function that runs \n",
    "#everytime trackbar changes) )\n",
    "cv2.createTrackbar(\"Hue_min\",\"TrackBars\",0,179,empty )\n",
    "cv2.createTrackbar(\"Hue_max\",\"TrackBars\",179,179,empty )\n",
    "cv2.createTrackbar(\"Sat_min\",\"TrackBars\",0,255,empty )\n",
    "cv2.createTrackbar(\"Sat_max\",\"TrackBars\",255,255,empty )\n",
    "cv2.createTrackbar(\"Val_min\",\"TrackBars\",0,255,empty )\n",
    "cv2.createTrackbar(\"Val_max\",\"TrackBars\",255,255,empty )\n",
    "\n",
    "#read trackbar values\n",
    "while(True):\n",
    "    h_min = cv2.getTrackbarPos(\"Hue_min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue_max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat_min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat_max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val_min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val_max\",\"TrackBars\")\n",
    "    \n",
    "    lower= np.array([h_min,s_min,v_min])\n",
    "    upper= np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "   \n",
    "    imgresult = cv2.bitwise_and(img,img,mask = mask)\n",
    "    \n",
    "    # print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "    \n",
    "    himage1=np.hstack((img,imgHSV))\n",
    "    \n",
    "   # vimgs= np.vstack((himage1,himage2))\n",
    "   \n",
    "    cv2.imshow('p3ict3ur',himage1)\n",
    " #   cv2.imshow('pictur',img)\n",
    "    cv2.imshow('result',imgresult)\n",
    "    #cv2.imshow('pictureHSV',imgHSV)\n",
    "    cv2.imshow('picturemask',mask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello cam show me not others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",600,240)\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "#cv2.createTrackbar(\"name\",\"nameoftrackbar\",minvalue,maxvalue(upto180 in opencv i.e. 179),function that runs \n",
    "#everytime trackbar changes) )\n",
    "cv2.createTrackbar(\"Hue_min\",\"TrackBars\",0,179,empty )\n",
    "cv2.createTrackbar(\"Hue_max\",\"TrackBars\",23,179,empty )\n",
    "cv2.createTrackbar(\"Sat_min\",\"TrackBars\",128,255,empty )\n",
    "cv2.createTrackbar(\"Sat_max\",\"TrackBars\",255,255,empty )\n",
    "cv2.createTrackbar(\"Val_min\",\"TrackBars\",166,255,empty )\n",
    "cv2.createTrackbar(\"Val_max\",\"TrackBars\",255,255,empty )\n",
    "\n",
    "#read trackbar values\n",
    "while(True):\n",
    "    \n",
    "    ret, img = cap.read() \n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    h_min = cv2.getTrackbarPos(\"Hue_min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue_max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat_min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat_max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val_min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val_max\",\"TrackBars\")\n",
    "    \n",
    "    lower= np.array([h_min,s_min,v_min])\n",
    "    upper= np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "   \n",
    "    imgresult = cv2.bitwise_and(img,img,mask = mask)\n",
    "    \n",
    "    # print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "\n",
    "    cv2.imshow('pictur',img)\n",
    "    cv2.imshow('result',imgresult)\n",
    "    cv2.imshow('pictureHSV',imgHSV)\n",
    "    cv2.imshow('picturemask',mask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "        \n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcontours(img):\n",
    "    contours, hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        #print(area)\n",
    "        cv2.drawContours(imgcont, cnt, -1, (255,0,47),3)\n",
    "        peri= cv2.arcLength(cnt,True)\n",
    "        #print(peri)\n",
    "        approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "        #print(len(approx))\n",
    "        if area>550:\n",
    "            cv2.drawContours(imgcont, cnt, -1, (255,0,0),2)\n",
    "            approx = cv2.approxPolyDP(cnt,0.01*peri,True)\n",
    "            objcorn = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            if objcorn==3: \n",
    "                objtype='Triangle'\n",
    "            elif objcorn == 4:\n",
    "                asp = w/float(h)\n",
    "                if asp >0.95 and asp<1.05:\n",
    "                    objtype = 'Square' \n",
    "                else:\n",
    "                        objtype='RECT'\n",
    "            elif objcorn>4:\n",
    "                objtype = 'Circle'\n",
    "            \n",
    "            else:\n",
    "                objtype='None'\n",
    "            \n",
    "            \n",
    "            cv2.rectangle(imgcont,(x,y),(x+w,y+h),(0,255,5),1)\n",
    "            cv2.putText(imgcont,objtype,((x+w//2)-10,(y+h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,0),2) \n",
    "            \n",
    "            \n",
    "            \n",
    "img = cv2.imread('shapes1.jpg')\n",
    "grayimg=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blurimg=cv2.GaussianBlur(grayimg, (3,3),2)\n",
    "output= cv2.Canny(blurimg,50,50)\n",
    "imgcont=img.copy()\n",
    "\n",
    "getcontours(output)\n",
    "\n",
    "\n",
    "cv2.imshow('pitre', imgcont)\n",
    "cv2.imshow('picccctre', img)\n",
    "cv2.imshow('picture',output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcontours(img):\n",
    "    contours, hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        #print(area)\n",
    "        \n",
    "        #print(len(approx))\n",
    "        if area>250:\n",
    "            cv2.drawContours(imgcont, cnt, -1, (255,0,47),3)\n",
    "            peri= cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt,0.01*peri,True)\n",
    "            objcorn = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            if objcorn==3: \n",
    "                objtype='Triangle'\n",
    "            elif objcorn == 4:\n",
    "                asp = w/float(h)\n",
    "                if asp >0.95 and asp<1.05:\n",
    "                    objtype = 'Square' \n",
    "                else:\n",
    "                        objtype='RECT'\n",
    "            elif objcorn>8:\n",
    "                objtype = 'Circle'\n",
    "            \n",
    "            else:\n",
    "                objtype='None'\n",
    "            \n",
    "            \n",
    "            cv2.rectangle(imgcont,(x,y),(x+w,y+h),(0,255,5),1)\n",
    "            cv2.putText(imgcont,objtype,((x+w//2)-10,(y+h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,0),2) \n",
    "            \n",
    "        \n",
    "cap = cv2.VideoCapture('v1.mp4')\n",
    "while(1): \n",
    "    ret, img = cap.read() \n",
    "    grayimg=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurimg=cv2.GaussianBlur(grayimg, (3,5),2)\n",
    "    output= cv2.Canny(blurimg,50,50)\n",
    "    imgcont=img.copy()\n",
    "\n",
    "    getcontours(output)\n",
    "    cv2.imshow('pitre', imgcont)\n",
    "    cv2.imshow('picccctre', img)\n",
    "    cv2.imshow('picture',output)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "        \n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"f4.jpg\")\n",
    "f_cascade = cv2.CascadeClassifier(r\"F:\\opencv\\opencv-master\\data\\haarcascades\\haarcascade_frontalface_default.xml\" )\n",
    "f_cascade1 = cv2.CascadeClassifier(r\"F:\\opencv\\opencv-master\\data\\haarcascades\\haarcascade_eye.xml\" )\n",
    "f_cascade2 = cv2.CascadeClassifier(r\"F:\\opencv\\opencv-master\\data\\haarcascades\\haarcascade_lowerbody.xml\" )\n",
    "f_cascade3 = cv2.CascadeClassifier(r\"F:\\opencv\\opencv-master\\data\\haarcascades\\haarcascade_upperbody.xml\" )\n",
    "imggray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = f_cascade.detectMultiScale(imggray,1.2,1)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),2)\n",
    "    cv2.putText(img,\"Face\",(x,y-10),cv2.FONT_HERSHEY_COMPLEX,0.2,(255,255,255),1)\n",
    "faces1 = f_cascade1.detectMultiScale(imggray,1.3,1)\n",
    "faces2 = f_cascade2.detectMultiScale(imggray,1.1,1)\n",
    "faces3 = f_cascade3.detectMultiScale(imggray,1.1,1)\n",
    "\n",
    "for x,y,w,h in faces1:\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),2)\n",
    "    cv2.putText(img,\"EYE\",(x,y-5),cv2.FONT_HERSHEY_COMPLEX,0.2,(0,0,255),1)\n",
    "\n",
    "for x,y,w,h in faces2:\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),2)\n",
    "    cv2.putText(img,\"lowerBODY\",(x,y-5),cv2.FONT_HERSHEY_COMPLEX,0.2,(255,0,255),1)\n",
    "\n",
    "for x,y,w,h in faces3:\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),2)\n",
    "    cv2.putText(img,\"upperbody\",(x,y-5),cv2.FONT_HERSHEY_COMPLEX,0.2,(0,250,0),1)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture(0)\n",
    "while (True):\n",
    "    ret, img = cap.read()\n",
    "    f_cascade = cv2.CascadeClassifier(r\"F:\\opencv\\opencv-master\\data\\haarcascades\\haarcascade_frontalface_default.xml\" )\n",
    "    imggray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = f_cascade.detectMultiScale(imggray,1.5,1)\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),2)\n",
    "        cv2.imshow(\"Image\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
